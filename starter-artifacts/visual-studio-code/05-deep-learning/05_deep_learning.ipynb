{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Train an autoencoder using GPU #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import azureml\n",
    "from azureml.core import Run\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "import pickle\n",
    "\n",
    "# Verify we have a GPU available\n",
    "# The output of the following should not be an empty array\n",
    "# If you get an empty array back, it means no GPU was detected, which might mean you need to \n",
    "# uninstall keras/tensorflow/tensorflow-gpu and then reinstall tensorflow-gpu and keras\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "# We use Fashion mnist dataset\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "# We download and load the data\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "# Build the encoder\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded_feature_vector = MaxPooling2D((2, 2), padding='same', name='feature_vector')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional compressed feature vector\n",
    "\n",
    "# Build the decoder\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded_feature_vector)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded_output = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "\n",
    "# The first model is autoencoder model, it takes the input image and results in a decoded image\n",
    "autoencoder_model = Model(input_img, decoded_output)\n",
    "# Compile the first model\n",
    "autoencoder_model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "\n",
    "# The second NN model is only a half of the first model, it take the input image and gives the encoded vector as output\n",
    "encoder_model = Model(inputs=autoencoder_model.input,\n",
    "                                 outputs=autoencoder_model.get_layer('feature_vector').output) # <---- take the output from the feature vector\n",
    "# Compile the second model\n",
    "encoder_model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "# We need to scale the image from [0-255] to [0-1] for better performance of activation functions\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "\n",
    "# We train the NN in batches (groups of images), so we reshape the dataset\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "print(\"Train dataset size is {0}\".format(x_train.shape))\n",
    "print(\"Test dataset size is {0}\".format(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Train a neural network #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It takes several minutes to train this neural network, depending on the configuration of your cluster.\n",
    "learning_history=autoencoder_model.fit(x=x_train, y=x_train, epochs=10, batch_size=128, \n",
    "                                 shuffle=True, validation_data=(x_test, x_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Test the model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_decoded_image=autoencoder_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Export and Register the model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide the Subscription ID of your existing Azure subscription\n",
    "subscription_id = \"xxx-xxx-xxx\"\n",
    "\n",
    "#Provide values for the Resource Group and Workspace that will be created\n",
    "resource_group = \"aml-workspace-z\"\n",
    "workspace_name = \"aml-workspace-z\"\n",
    "workspace_region = 'westcentralus' # eastus, westcentralus, southeastasia, australiaeast, westeurope\n",
    "\n",
    "# By using the exist_ok param, if the worskpace already exists we get a reference to the existing workspace instead of an error\n",
    "ws = Workspace.create(\n",
    "    name = workspace_name,\n",
    "    subscription_id = subscription_id,\n",
    "    resource_group = resource_group, \n",
    "    location = workspace_region,\n",
    "    exist_ok = True)\n",
    "\n",
    "print(\"Workspace Provisioning complete.\")\n",
    "\n",
    "# Serialize the model to a pickle file in the outputs folder\n",
    "model_name = 'autoencoder'\n",
    "import os\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "output_model_path = 'outputs/' + model_name + '.pkl'\n",
    "autoencoder_model.save(output_model_path)\n",
    "print('Exported model to ', output_model_path)\n",
    "# notice for the model_path, we supply the name of the outputs folder without a trailing slash\n",
    "registered_model = azureml.core.model.Model.register(model_path='outputs', model_name=model_name, workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (azure_automl)",
   "language": "python",
   "name": "azure_automl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

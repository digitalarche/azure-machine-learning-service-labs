{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - load the data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"Current working directory is \", os.path.abspath(os.path.curdir))\n",
    "df = pd.read_csv('./data/UsedCars_Clean.csv', delimiter=',')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - add the affordable feature #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Affordable'] = np.where(df['Price'] < 12000, 1, 0)\n",
    "df_affordability = df[[\"Age\", \"KM\", \"Affordable\"]]\n",
    "print(df_affordability.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Scale the numeric feature values #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_affordability[[\"Age\", \"KM\"]].values.astype(float)\n",
    "y = df_affordability[[\"Affordable\"]].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(pd.DataFrame(X).describe().round(2))\n",
    "print(pd.DataFrame(X_scaled).describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Fit a Logistic Regression #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Create a linear model for Logistic Regression\n",
    "clf = linear_model.LogisticRegression(C=1, solver='lbfgs')\n",
    "\n",
    "# we create an instance of Classifier and fit the data.\n",
    "clf.fit(X_scaled, y.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Test the trained model's prediction #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = 60\n",
    "km = 40000\n",
    "\n",
    "scaled_input = scaler.transform([[age, km]])\n",
    "prediction = clf.predict(scaled_input)\n",
    "\n",
    "print(\"Can I afford a car that is {} month(s) old with {} KM's on it?\".format(age, km))\n",
    "print(\"Yes (1)\" if prediction[0] == 1 else \"No (0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Measure the model's performance #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_inputs = scaler.transform(X)\n",
    "predictions = clf.predict(scaled_inputs)\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(y, predictions)\n",
    "print(\"Model Accuracy: {}\".format(score.round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 - Define a method to experiment with different training subset sizes #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_X = df_affordability[[\"Age\", \"KM\"]]\n",
    "full_Y = df_affordability[[\"Affordable\"]]\n",
    "\n",
    "def train_eval_model(full_X, full_Y, training_set_percentage):\n",
    "    \n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, \n",
    "                                                        train_size=training_set_percentage, \n",
    "                                                        test_size=1.0-training_set_percentage, \n",
    "                                                        random_state=42)\n",
    "    \n",
    "    train_X = train_X.values.astype(float)\n",
    "    train_Y = train_Y.values.ravel()\n",
    "    test_X = test_X.values.astype(float)\n",
    "    test_Y = test_Y.values.ravel()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(train_X)\n",
    "    \n",
    "    clf = linear_model.LogisticRegression(C=1, solver='lbfgs')\n",
    "    clf.fit(X_scaled, train_Y)\n",
    "\n",
    "    scaled_inputs = scaler.transform(test_X)\n",
    "    predictions = clf.predict(scaled_inputs)\n",
    "    score = accuracy_score(test_Y, predictions)\n",
    "\n",
    "    return (clf, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 - Verify AML SDK Installed #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "\n",
    "print(\"SDK Version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9 - Create a workspace #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the Subscription ID of your existing Azure subscription\n",
    "subscription_id = \"xxx-xxx-xxx\"\n",
    "\n",
    "# Provide values for the Resource Group and Workspace that will be created\n",
    "resource_group = \"service-labs\"\n",
    "workspace_name = \"service-labs-ws\"\n",
    "workspace_region = 'eastus'  # eastus, westcentralus, southeastasia, australiaeast, westeurope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "\n",
    "# import the Workspace class\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.create(\n",
    "    name=workspace_name,\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group=resource_group,\n",
    "    location=workspace_region,\n",
    "    exist_ok=True)\n",
    "\n",
    "print(\"Workspace Provisioning complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10 - Create an experiment and log metrics for multiple training runs #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.run import Run\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "# start a training run by defining an experiment\n",
    "myexperiment = Experiment(ws, \"UsedCars_Experiment\")\n",
    "root_run = myexperiment.start_logging()\n",
    "\n",
    "training_set_percentage = 0.25\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage)\n",
    "print(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "training_set_percentage = 0.5\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage)\n",
    "print(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "training_set_percentage = 0.75\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage)\n",
    "print(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "training_set_percentage = 0.9\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage)\n",
    "print(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "# Close out the experiment\n",
    "root_run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11 - Review captured runs #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the Azure Portal, find your Azure Machine Learning Workspace, \n",
    "#select Experiments and select the UsedCars_Experiment\n",
    "\n",
    "# You can also query the run history using the SDK.\n",
    "# The following command lists all of the runs for the experiment\n",
    "runs = [r for r in root_run.get_children()]\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12 - Create an AML Compute #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.get(name=workspace_name, subscription_id=subscription_id,resource_group=resource_group)\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep = '\\t')\n",
    "\n",
    "experiment_name = \"UsedCars_ManagedCompute_01\"\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "batchai_cluster_name = \"UsedCars-02\"\n",
    "cluster_min_nodes = 1\n",
    "cluster_max_nodes = 3\n",
    "vm_size = \"STANDARD_DS11_V2\"\n",
    "\n",
    "\n",
    "if batchai_cluster_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[batchai_cluster_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found existing compute target, using this compute target instead of creating:  ' + \n",
    "              batchai_cluster_name)\n",
    "    else:\n",
    "        print(\"Error: A compute target with name \", batchai_cluster_name,\n",
    "              \" was found, but it is not of type AmlCompute.\")\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size, # NC6 is GPU-enabled\n",
    "                                                                min_nodes = cluster_min_nodes, \n",
    "                                                                max_nodes = cluster_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current BatchAI cluster status, use the 'status' property    \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 13 - Upload the dataset to the DataStore #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "ds.upload(src_dir='./data', target_path='used_cars', overwrite=True, show_progress=True)\n",
    "\n",
    "# Prepare batch training script\n",
    "# - See ./training/train.py\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 14 - Create estimator #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "    '--training-set-percentage': 0.3\n",
    "}\n",
    "\n",
    "est_config = Estimator(source_directory='./training',\n",
    "                       script_params=script_params,\n",
    "                       compute_target=compute_target,\n",
    "                       entry_script='train.py',\n",
    "                       conda_packages=['scikit-learn', 'pandas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 15 - Execute the estimator job #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config=est_config)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the run to complete by executing the following cell. Note that this process will perform the following:\n",
    "- Build and deploy the container to Azure Machine Learning compute (~8 minutes)\n",
    "- Execute the training script (~2 minutes)\n",
    "\n",
    "If you change only the training script and re-submit, it will run faster the second time because the necessary container is already prepared so the time requried is just that for executing the training script.\n",
    "\n",
    "Run the cell below, and wait for run **Status** to be **Completed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, if you are using **Visual Studio Code**, the RunDetails widget is currently not supported. Uncomment the line below and run the cell to monitor and wait for the experiment run to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the recorded metrics from the run\n",
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
